{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load example\n",
    "The examples below show how to load the EEG data, fNIRS data, and labels.\n",
    "\n",
    "The functions are also defined in `load_REFED.py`:\n",
    "```python\n",
    "from load_REFED import load_data, load_feature, load_labels\n",
    "```\n",
    "\n",
    "Main functions:\n",
    "- `load_data(data_path, sub_list, modality)` to load raw data / processed data.\n",
    "- `load_feature(data_path, sub_list, modality)` to load extracted features.\n",
    "- `load_labels(data_path, sub_list, dimension)` to load labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat, savemat\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data         = './REFED-dataset/data'\n",
    "path_preprocessed = './REFED-dataset/preprocessed'\n",
    "path_feature      = './REFED-dataset/features'\n",
    "path_annotation   = './REFED-dataset/annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The following functions are used to load data, features, and labels.\n",
    "Also defined in `load_REFED.py`\n",
    "'''\n",
    "\n",
    "def load_data(data_path, sub_list=None, modality:list=['EEG', 'fNIRS']):\n",
    "    '''\n",
    "    Load EEG and fNIRS data for specified subjects and modalities.\n",
    "    Parameters:\n",
    "        data_path (str): Path to the data directory.\n",
    "        sub_list (list, optional): List of subject identifiers to load. If None, load all subjects.\n",
    "        modality (list, optional): List of modalities to load ('EEG', 'fNIRS'). Default is both.\n",
    "    Returns:\n",
    "        data (dict): Nested dictionary with structure data[subject][modality][video].\n",
    "    '''\n",
    "    data = {}\n",
    "    if sub_list is None:\n",
    "        sub_list = os.listdir(data_path)\n",
    "    \n",
    "    for si in sub_list:\n",
    "        # Determine whether it is the subject folder\n",
    "        if os.path.isdir(os.path.join(data_path, si)):\n",
    "            data[si] = {}\n",
    "            # Read EEG and F-NIRS data\n",
    "            if 'EEG' in modality:\n",
    "                path_si_EEG = os.path.join(data_path, si, 'EEG_videos.mat')\n",
    "                data_si_EEG = loadmat(path_si_EEG)\n",
    "                data[si]['EEG'] = {'v%d'%vi :data_si_EEG['video_%d' % vi] for vi in range(1,16)}\n",
    "                del data_si_EEG\n",
    "            if 'fNIRS' in modality:\n",
    "                path_si_fNIRS = os.path.join(data_path, si, 'fNIRS_videos.mat')\n",
    "                data_si_fNIRS = loadmat(path_si_fNIRS)\n",
    "                data[si]['fNIRS'] = {'v%d'%vi:data_si_fNIRS['video_%d' % vi] for vi in range(1,16)}\n",
    "                del data_si_fNIRS\n",
    "            gc.collect()\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def load_feature(data_path, sub_list=None, modality:list=['EEG', 'fNIRS']):\n",
    "    '''\n",
    "    Load EEG and fNIRS features for specified subjects and modalities.\n",
    "    Parameters:\n",
    "        data_path (str): Path to the feature directory.\n",
    "        sub_list (list, optional): List of subject identifiers to load. If None, load all subjects.\n",
    "        modality (list, optional): List of modalities to load ('EEG', 'fNIRS'). Default is both.\n",
    "    Returns:\n",
    "        data (dict): Nested dictionary with structure data[subject][modality][video].\n",
    "    '''\n",
    "    data = {}\n",
    "    if sub_list is None:\n",
    "        sub_list = os.listdir(data_path)\n",
    "    \n",
    "    for si in sub_list:\n",
    "        # Judge whether it is the subject folder\n",
    "        if os.path.isdir(os.path.join(data_path, si)):\n",
    "            data[si] = {}\n",
    "            # Read EEG and fNIRS data\n",
    "            if 'EEG' in modality:\n",
    "                path_si_EEG = os.path.join(data_path, si, 'EEG_videos_feature.mat')\n",
    "                data_si_EEG = loadmat(path_si_EEG)\n",
    "                data[si]['EEG'] = {'v%d'%vi :data_si_EEG['video_%d' % vi] for vi in range(1,16)}\n",
    "                del data_si_EEG\n",
    "            if 'fNIRS' in modality:\n",
    "                path_si_fNIRS = os.path.join(data_path, si, 'fNIRS_videos_feature.mat')\n",
    "                data_si_fNIRS = loadmat(path_si_fNIRS)\n",
    "                data[si]['fNIRS'] = {'v%d'%vi:data_si_fNIRS['video_%d' % vi] for vi in range(1,16)}\n",
    "                del data_si_fNIRS\n",
    "            gc.collect()\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def load_label(data_path, sub_list=None, dimension:list=['Valence', 'Arousal']):\n",
    "    '''\n",
    "    Load labels for specified subjects and dimensions.\n",
    "    Parameters:\n",
    "        data_path (str): Path to the label directory.\n",
    "        sub_list (list, optional): List of subject identifiers to load. If None, load all subjects.\n",
    "        dimension (list, optional): List of dimensions to load ('Valence', 'Arousal'). Default is both.\n",
    "    Returns:\n",
    "        label (dict): Nested dictionary with structure label[subject][video][dimension].\n",
    "    '''\n",
    "    label = {}\n",
    "    if sub_list is None:\n",
    "        sub_file = os.listdir(data_path)\n",
    "    else:\n",
    "        sub_file = ['s%s_label.mat' % si for si in sub_list]\n",
    "        \n",
    "    for si in sub_file:\n",
    "        if si.endswith('_label.mat'):\n",
    "            si_key = 's%s' % si[:-10]\n",
    "            file_path = os.path.join(data_path, si)\n",
    "            label_si = loadmat(file_path)\n",
    "            \n",
    "            label[si_key] = {}\n",
    "            for vi in range(1,16):\n",
    "                vi_key = 'v%d' % vi\n",
    "                label[si_key][vi_key] = {}\n",
    "                if 'Valence' in dimension:\n",
    "                    label[si_key][vi_key]['Valence'] = label_si['video_%d' % vi][:, 0]\n",
    "                if 'Arousal' in dimension:\n",
    "                    label[si_key][vi_key]['Arousal'] = label_si['video_%d' % vi][:, 1]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load raw data\n",
    "This needs enough memory to load all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data(path_data, modality=['fNIRS']) # 6GB memory needed\n",
    "load_data(path_data, modality=['EEG'])   # 25GB memory needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data(path_preprocessed) # 10GB memory needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_feature(path_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_label(path_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
